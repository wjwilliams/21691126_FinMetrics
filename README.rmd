---
output:
  md_document:
    variant: markdown_github
---

# Purpose

This is the READMe of my practical Examination for Financial Econometrics


```{r}

rm(list = ls()) # Clean your environment:
gc() # garbage collection - It can be useful to call gc after a large object has been removed, as this may prompt R to return memory to the operating system.
library(tidyverse)
list.files('Question 1/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question 2/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question 3/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question 4/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question 5/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
list.files('Question 6/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
```

# Question 1: AI Fund
Please note that I saved my powerpoint in my main question folder as I have gitignored my data folder so it will not be uploaded to github.
```{r}
# Let's read in the data first and foremost and have a look at it
library(tidyverse)
library(lubridate)
library(tbl2xts) 
library(PerformanceAnalytics)
library(fmxdat)

ASISA <- read_rds("Question 1/data/ASISA_Rets.rds")
BM <- read_rds("Question 1/data/Capped_SWIX.rds")
AI_Fund <- read_rds("Question 1/data/AI_Max_Fund.rds")

# View(ASISA)
# View(BM)
# View(AI_Fund)
#Notes: We are given monthly returns for all funds 
```

```{r}
#Lets start by identifying what I actually want to get done:
# 1) Plot the cumulative returns for all of the funds
# 2) then Plot the actively managed fund including fees
# 3) Plot the 3 year rolling returns (including fees)
# 4) Try and plot the actual distribution of the returns for all three funds
```

```{r}
#This code chunk wrangles the data to join all of the returns so we can plot them
# First we need to select managers to compare to, I think it would be a good idea to  get the top of active managers funds as well as the bottom and then  compare to the AI and capped SWIX

strat_active <- ASISA %>% 
    filter(Index == "No") %>% #we do not want any indecies
    filter(FoF == "No") %>%  #We do not want any FoFs
    select(-Index, - FoF)

#Now i need to get the tickers of the funds that have existed since 2005
ticker_to_include <- strat_active %>% 
     filter(date < ymd(20050101)) %>% 
    pull(Fund)

best_active <- strat_active %>% 
    arrange(date) %>% 
    filter(Fund %in% ticker_to_include) %>% #want to make sure that the funds have been around for a comparable amount of time
    group_by(Fund) %>% 
    mutate(avg = mean(Returns)) %>%
    ungroup() %>% # Now we have the average for all the funds 
    filter(date == last(date)) %>% 
    filter(date > lubridate::ymd(20230101)) %>% # I only want funds that exist in 2023 to compare to AI
    filter(avg == max(avg)) %>% #Get the best fund
    pull(Fund)

worst_active <- strat_active %>% 
    arrange(date) %>% 
    filter(Fund %in% ticker_to_include) %>%
    group_by(Fund) %>% 
    mutate(avg = mean(Returns)) %>%
    ungroup() %>% # Now we have the average for all the funds 
    filter(date == last(date)) %>% 
    filter(date > lubridate::ymd(20230101)) %>% # I only want funds that exist in 2023 to compare to AI
    filter(avg == min(avg)) %>% #Get the worst fund
    pull(Fund)

median_active <- 
  strat_active %>% 
    arrange(date) %>% 
    filter(Fund %in% ticker_to_include) %>%
    group_by(Fund) %>% 
    mutate(avg = mean(Returns)) %>%
    ungroup() %>% # Now we have the average for all the funds 
    filter(date == last(date)) %>% 
    filter(date > lubridate::ymd(20230101)) %>% # I only want funds that exist in 2023 to compare to AI
    arrange(avg) %>% # Get the funds with the median average return
    slice(n()/2) %>% 
    pull(Fund)


#Now just clean the managers df
managers <- strat_active %>% 
    filter(Fund %in% c(worst_active, best_active, median_active)) %>% 
    spread(Fund, Returns) %>% 
    rename("Best" = "N924", "Worst" = "V906", "Median" = "B444")


#now I can join all three of the dfs so that I have 1 df to use with all of the returns of interest
full_df <- 
    
    left_join(AI_Fund, managers, by = "date") %>% 
    left_join(., BM %>% select(-Tickers) %>% rename("Benchmark"= "Returns"), by = "date") 

#lets be fancy and use the impute_missing_returns func from the tut to get the returns for the active funds
final_df <- impute_missing_returns(full_df, impute_returns_method = "Drawn_Distribution_Own")

#last but not least lets get it in tidy format
final_df <- final_df %>% gather(Tickers, ret, -date)

#Now we are off to the races and can plot the returns
    
```
## Fees 
```{r}
#Lets now just plot the cumulative returns
cum_plot<- final_df %>% 
    arrange(date) %>% 
    group_by(Tickers) %>% 
    mutate(cum_rts = cumprod(1+ret)) %>% 
    select(-ret) %>% 
    ungroup() %>% 
    ggplot()+
    geom_line(aes(date, cum_rts, color = Tickers))+
    fmxdat::theme_fmx()+
    labs(title = "Cumulative Returns of All Funds", subtitle = "Without fees", x = "Date", y = "Cumulative Returns")
  #Save it to the graphs folder to use in the powerpoint
# ggsave(file.path("graphs/","Cumulative Returns of All Funds.png"), plot = cum_plot, width = 6, height = 5 )
  
cum_plot
```

```{r}
#Now lets add fees on to the actively manaaed portfolios, lets take a fee of 200bps
#Lets include the fee converter func from the prac
 feeconverter <- function(x, Ann_Level) (1+x)^(1/Ann_Level)-1

managers_fees <- managers %>% 
    gather(Tickers, returns, -date) %>% 
    mutate(fee_rts = returns - feeconverter(200*1e-4, Ann_Level = 12)) %>% #using a fee of 25bps
    select(-returns) %>% 
    spread(Tickers, fee_rts) 

#Now we can just join this to the final df
fee_finaldf <- final_df %>% 
    spread(Tickers, ret) %>% 
    select(-Best, -Worst, -Median) %>% 
    left_join(., managers_fees, by = "date")

#Again we can impute missing values
fee_finaldf<- impute_missing_returns(fee_finaldf, impute_returns_method = "Drawn_Distribution_Own")

#Make it tidy to plot again
fee_finaldf<-fee_finaldf %>% 
    gather(Tickers, ret, -date) 

Cum_fee_plot<-fee_finaldf %>% 
arrange(date) %>% 
    group_by(Tickers) %>% 
    mutate(cum_rts = cumprod(1+ret)) %>% 
    select(-ret) %>% 
    ungroup() %>% 
    ggplot()+
    geom_line(aes(date, cum_rts, color = Tickers))+
    fmxdat::theme_fmx()+
    labs(title = "Cumulative Returns of All Funds", subtitle = "With fees", x = "Date", y = "Cumulative Returns")
#Save it to the graphs folder to use in the powerpoint
# ggsave(file.path("graphs/","Cumulative Returns of All Funds with fees.png"), plot = Cum_fee_plot, width = 6, height = 5 )

Cum_fee_plot
```
## Rolling Returns

```{r}
library(RcppRoll)

#We have monthly returns after fees so we can use the Rcpproll package to get the rolling returns
roll_fee <- fee_finaldf %>% 
    group_by(Tickers) %>% 
    mutate(RollRets = RcppRoll::roll_prod(1 + ret, 24, fill = NA, 
    align = "right")^(12/24) - 1) %>% 
    group_by(date) %>% filter(any(!is.na(RollRets))) %>% 
ungroup()

roll_ret_plot<- 
roll_fee %>% 
ggplot() + 
geom_line(aes(date, RollRets, color = Tickers), alpha = 0.7, 
    size = 1) + 
labs(title = " Rolling 2 Year Annualized Returns", 
    subtitle = "", x = "", y = "Rolling 2 year Returns "
    ) + fmxdat::theme_fmx()

#Save it to the graphs folder to use in the powerpoint
# ggsave(file.path("graphs/","Rolling 2 Year Annualized Returns.png"), plot = roll_ret_plot, width = 6, height = 5 )


roll_ret_plot
```

```{r}
#Lets now try and plot the rolling density function with the medians 
roll_density<- roll_fee %>% 
ggplot(aes(x = RollRets)) + 
geom_density(aes(fill = Tickers), alpha =0.6)+
      geom_vline(data = . %>% filter(Tickers == "AI_Fund") %>% summarise(median = median(RollRets)),
             aes(xintercept = median),
             linetype = "dashed", color = "red")+
      geom_vline(data = . %>% filter(Tickers == "Benchmark") %>% summarise(median = median(RollRets)),
             aes(xintercept = median),
             linetype = "dashed", color = "orange")+
      geom_vline(data = . %>% filter(Tickers == "Best") %>% summarise(median = median(RollRets)),
             aes(xintercept = median),
             linetype = "dashed", color = "green")+
      geom_vline(data = . %>% filter(Tickers == "Worst") %>% summarise(median = median(RollRets)),
             aes(xintercept = median),
             linetype = "dashed", color = "purple")+
    geom_vline(data = . %>% filter(Tickers == "Median") %>% summarise(median = median(RollRets)),
             aes(xintercept = median),
             linetype = "dashed", color = "blue")+
    labs(title = " Rolling 2 year densities of the different funds", 
    subtitle = "", x = "", y = "Rolling 2 year Returns "
    ) + fmxdat::theme_fmx()
#Save it to the graphs folder to use in the powerpoint
# ggsave(file.path("graphs/","Rolling 2 year densities of the different funds.png"), plot = roll_density, width = 6, height = 5 )

roll_density
```

## Rolling annualized Standard Deviation
```{r}

#Now I do the same thing to get the rolling SD
rollsd_fee <- fee_finaldf %>% 
    group_by(Tickers) %>%
    mutate(RollSD = RcppRoll::roll_sd(1 + ret, 36, fill = NA, align = "right") * 
    sqrt(12)) %>% 
filter(!is.na(RollSD))

sd_plot<- rollsd_fee %>% 
ggplot() + 
geom_line(aes(date, RollSD, color = Tickers), alpha = 0.7, size = 1.25) + 
    
labs(title = "Rolling 3 Year Annualized SD ", x = "", y = "Rolling 2 year SD") + theme_fmx()

#Save it to the graphs folder to use in the powerpoint
# ggsave(file.path("graphs/","Rolling 2 Year Annualized S.png"), plot = sd_plot, width = 6, height = 5 )


sd_plot
```

# Question 2: Currency Hedging Analysis


```{r}
library(tidyverse)
library(fmxdat)
library(PerformanceAnalytics)
library(tbl2xts)
Indexes <- read_rds("Question 2/data/Cncy_Hedge_Assets.rds")
ZAR <- read_rds("Question 2/data/Monthly_zar.rds")


```



## Introduction 
I start by replicating the figure given in the article. I then construct a hedged and un-hedged portfolio, calculate their three year rolling returns and standard deviation. Lastly, I compare the annualised returns and standard deviations over three different time periods to show that the results hold.

```{r}
#Lets start by constructing the porfolio, I want to optimise it using quadprog
# library(quadprog)
# #need to get rid of the dates to estimate Sigma
# return_mat_nodate <- data.matrix(Indexes[,-1])
# 
# library(RiskPortfolios)
# library(fitHeavyTail)
# #now use the RiskPortfolios or fitheavy tail packages to get sigma
# 
# HTT <- fitHeavyTail::fit_mvt(return_mat_nodate)
# Sigma <- HTT$cov
# mu <- HTT$mu
# 
# #make sure that the matrix is positive defninite
# Sigma <- as.matrix( Matrix::nearPD(Sigma)$mat)
# #now I am going to construct the amat and bvec to use quadprog to solve there are 4 assets where the first is global equity, the second is global bonds, the third is local equity and the last is local bonds therefore
# Amat <- matrix(c(1, 1, 0, 0, 1,
#                 1, 1, 0, 1, 0,
#                 1, 0, 1, 0, 1,
#                 1, 0, 1, 1, 0), 
#                  nrow = 4, 
#                  byrow = TRUE)
# bvec <- c(1, 0.3, 0.7, 0.4, 0.6 )
# 
# meq = 1 #only the first constraint must hold with equality
# w.opt <- 
#     quadprog::solve.QP(Dmat = Sigma,
#                             dvec = mu, 
#                             Amat = Amat, 
#                             bvec = bvec, 
#                             meq = meq)$solution
# w.opt
# 
# result.QP <- tibble(stocks = colnames(Sigma), weight = w.opt) 


# #That did not work so I am rarther going to use porfolio analytics to construct the optimal portfolio
# library(PortfolioAnalytics)
# library(tbl2xts)
# indexes <- Indexes %>% 
#     tbl_xts()
# 
# specifications <- portfolio.spec(colnames(indexes))
# specifications <- add.constraint(portfolio = specifications, type = "full_investment")
# specifications <- add.constraint(portfolio = specifications, type = "long_only")
# specifications <- add.constraint(portfolio = specifications, type = "group", groups = list(c(1,2)), group_max = 0.3, group_min = 0)
# specifications <- add.constraint(portfolio = specifications, type = "group", groups = list(c(3,4)), group_max = 0.7, group_min = 0)
# specifications <- add.constraint(portfolio = specifications, type = "group", groups = list(c(2,4)), group_max = 0.4, group_min = 0)
# specifications <- add.constraint(portfolio = specifications, type = "group", groups = list(c(1,3)), group_max = 0.6, group_min = 0)
# # specifications<- add.constraint(portfolio=specifications, type="box", min=0, max=c(0.18, 0.12, 0.42, 0.28))
# 
# rand_port <- random_portfolios(portfolio=specifications, permutations = 1000, rp_method ='sample')
# 
# optimal <- optimize.portfolio(R = indexes, portfolio = specifications, optimize_method = "random", rp = rand_port, trace = TRUE)

#This did not work either so i am just going to constrict the weighst by hand that fit the constraints eg offshore bonds can only be 30% of the 40% allocation to bonds

weights <- c(0.18, 0.12, 0.42, 0.28)

#now i am just adding a column with the weights and assuming it is an index rather than a portfolio so there are no rebalancing days
port_ret <- Indexes %>% 
    mutate(MSCI_ACWI_wt = 0.18) %>% 
    mutate(Bbg_Agg_wt = 0.12) %>% 
    mutate(J433_wt = 0.28) %>% 
    mutate(ALBI_wt= 0.28) %>% 
    mutate(port_ret =(MSCI_ACWI*MSCI_ACWI_wt)+ (Bbg_Agg*Bbg_Agg_wt)+ (J433*J433_wt)+(ALBI*ALBI_wt)) %>% 
    select(date, port_ret)

#Now I need to calculate the returns of the dollar rand exchange rate

ex_ret <- ZAR %>% 
    arrange(date) %>% 
    mutate(currency_ret = value/lag(value)-1) %>% 
    select(date, currency_ret) %>% 
    slice(-1)


#now we can join the two data frames
full_df <- port_ret %>% 
    left_join(., ex_ret, by = "date")
```

```{r }
#In order to get the percentages on the graph we need to identify how many observations are in each section where the top and bottom left quadrant we also need to consider the fee which appears to be about three percent
countingdf <- full_df %>% 
    na.omit() #This just gets rid of the nas
no_obs <- nrow(countingdf) #get the total number of observations so that we can actually get the percentages

#top right quandrant percentage calculation
TR_perc <- countingdf %>% 
    filter(port_ret >0) %>% 
    filter(currency_ret>0) %>% 
    nrow()/no_obs*100 
TR_perc <- round(TR_perc,0)

#botom right quadrant percentage calculation
BR_perc <- countingdf %>% 
    filter(port_ret <0) %>% 
    filter(currency_ret>0) %>% 
    nrow()/no_obs*100 
 BR_perc<-   round(BR_perc,0)

#top left quandrant percentage calculation
TL_perc <- countingdf %>% 
    filter(port_ret >0) %>% 
    filter(currency_ret<0) %>% 
    nrow()/no_obs*100
 TL_perc<- round(TL_perc,0)

#bottom left quandrant percentage calculation
BL_perc <- countingdf %>% 
    filter(port_ret <0) %>% 
    filter(currency_ret<0) %>% 
    nrow()/no_obs*100 
  BL_perc<-  round(BL_perc,0)

#Top left with fees quandrant percentage calculation
TLF_perc <- countingdf %>% 
    filter(port_ret >0) %>% 
    filter(currency_ret< -0.03) %>% 
    nrow()/no_obs*100 
 TLF_perc<-   round(TLF_perc,0)

#Bottom left with fees quandrant percentage calculation
BLF_perc <- countingdf %>% 
    filter(port_ret <0) %>% 
    filter(currency_ret< -0.03) %>% 
    nrow()/no_obs*100  
  BLF_perc<-  round(BLF_perc,0)

library(ggExtra)
library(glue)
#Now lets actually try and get the plot from ghost 
scatter_plot <- ggplot(full_df)+
    annotate("rect", xmin= 0, xmax = -Inf, ymin = 0, ymax = Inf, fill ="orange", alpha =0.5)+#top left quandrant
    annotate("rect", xmin= 0, xmax = -Inf, ymin = 0, ymax = -Inf, fill ="red", alpha =0.5)+#bottom left quandrant
    annotate("rect", xmin= 0, xmax = Inf, ymin = 0, ymax = Inf, fill ="green", alpha =0.5)+#top right quandrant
    annotate("rect", xmin= 0, xmax = Inf, ymin = 0, ymax = -Inf, fill ="green", alpha =0.2)+#bottom left quandrant
    geom_point(aes(x = currency_ret, y = port_ret), colour = "grey", alpha = 0.8)+
    geom_smooth(aes(x = currency_ret, y = port_ret),method = "lm")+
    geom_hline(yintercept = 0)+
    geom_vline(xintercept = 0)+
    geom_vline(xintercept = -0.03, linetype = "dashed")+
    geom_label(aes(x = -0.1, y = 0.1, label = "Hedge works but, amplifies Volatility"), color = "black", size = 2)+
    geom_label(aes(x = -0.1, y = -0.1, label = "Best case for hedge:\\ higher return lower volatility"), color = "black", size = 2) +
    geom_label(aes(x = 0.1, y = 0.1, label = "Hedge throws away returns"), color = "black", size = 2) +
    geom_label(aes(x = 0.1, y = -0.1, label = "Hedge removes currency cushion"), color = "black", size = 2)+
    geom_label(aes(x = -0.17, y = 0.17, label = glue("{TL_perc}%")), color = "black", size = 3)+
    geom_label(aes(x = -0.17, y = -0.17, label = glue("{BL_perc}%")), color = "black", size = 3)+
    geom_label(aes(x = 0.17, y = 0.17, label = glue("{TR_perc}%")), color = "black", size = 3)+
    geom_label(aes(x = 0.17, y = -0.17, label = glue("{BR_perc}%")), color = "black", size = 3)+
    geom_label(aes(x = -0.17, y = 0.17, label = glue("{TL_perc}%")), color = "black", size = 3)+
    geom_label(aes(x = -0.05, y = -0.17, label = glue("{BLF_perc}%")), color = "black", size = 3)+
    geom_label(aes(x = -0.05, y = 0.17, label = glue("{TLF_perc}%")), color = "black", size = 3)+

    labs(title = "Scatter Plot of USD/ZAR and Portfolio returns ", x = "USD-ZAR Returns", y = "60-40 Local-Global Returns")+
    lims(x = c(-0.2, 0.2), y = c(-0.2, 0.2)) +  # Set axis limits
    theme_bw()



scatter_plot_density <- ggMarginal(scatter_plot, type = "density", margins = "both", fill = "blue")

scatter_plot_density

```












# Volatility analysis
```{r}

#Lets use the fee converter again assuming that there are fees for hedging assuming the same three percent as above
 feeconverter <- function(x, Ann_Level) (1+x)^(1/Ann_Level)-1

#The hedged return is exactly the return of the global assets less the fee to hedge
hedged<- Indexes %>% 
    mutate(MSCI_ACWI_wt = 0.18) %>% 
    mutate(Bbg_Agg_wt = 0.12) %>% 
    mutate(J433_wt = 0.28) %>% 
    mutate(ALBI_wt= 0.28) %>% 
    mutate(hedged_ret =(MSCI_ACWI*MSCI_ACWI_wt)+ (Bbg_Agg*Bbg_Agg_wt)+ (J433*J433_wt)+(ALBI*ALBI_wt) - feeconverter(300*1e-4, Ann_Level = 12)) %>% 
    select(date, hedged_ret)

unhedged <- Indexes %>% 
    left_join(., ex_ret, by ="date") %>% 
    filter(!is.na(currency_ret)) %>% 
    mutate(MSCI_ACWI_wt = 0.18) %>% 
    mutate(Bbg_Agg_wt = 0.12) %>% 
    mutate(J433_wt = 0.28) %>% 
    mutate(ALBI_wt= 0.28) %>% 
    mutate(unhedged_ret =((MSCI_ACWI*MSCI_ACWI_wt)+ (Bbg_Agg*Bbg_Agg_wt))*currency_ret + (J433*J433_wt)+(ALBI*ALBI_wt)) %>% #here the global assets are subject to the volatility of the rand
    select(date, unhedged_ret)

#Now we can join the dfs so we can compare the returns and the volatility
hedged_comp_df <-
    left_join(unhedged, hedged, by = "date") %>% 
    rename("Hedged"= "hedged_ret", "Unhedged"= "unhedged_ret")

#Lets get the annulised returns for both portfolios
#Start by getting tidy data
tidy_hedged <-hedged_comp_df
```


```{r}
#Now lets plot the rollinf returns and SD
#Let's again use the RcppRoll package agin to get annualised reterns and volatility
library(RcppRoll)

roll_ret_hedge <- hedged_comp_df %>% 
    gather(Type, ret, -date) %>% #here type refers to whether it is hedged or not
    group_by(Type) %>% 
    mutate(RollRets = RcppRoll::roll_prod(1 + ret, 24, fill = NA, 
    align = "right")^(12/24) - 1) %>% 
    group_by(date) %>% filter(any(!is.na(RollRets))) %>% 
ungroup()

roll_ret_hedge_plot<- 
roll_ret_hedge %>% 
ggplot() + 
geom_line(aes(date, RollRets, color = Type), alpha = 0.7, 
    size = 1) + 
labs(title = " Rolling 2 Year Annualized Returns", 
    subtitle = "", x = "", y = "Rolling 2 year Returns "
    ) + fmxdat::theme_fmx()

roll_ret_hedge_plot
```
Figure 2 incorporates the fee identified in the study and in Figure Figure 1. Once the fee has been accounted for it is clear to see the that unhedged portfolio almost always outperforms it's hedged counterpart.
```{r}
#Now lets get the rolling sd as a measure of volatility

roll_SD_hedge <-  hedged_comp_df %>% 
    gather(Type, ret, -date) %>% 
    group_by(Type) %>%
    mutate(RollSD = RcppRoll::roll_sd(1 + ret, 36, fill = NA, align = "right") * 
    sqrt(12)) %>% 
filter(!is.na(RollSD))

roll_SD_hedge_plot<- roll_SD_hedge %>% 
ggplot() + 
geom_line(aes(date, RollSD, color = Type), alpha = 0.7, size = 1.25) + 
    
labs(title = "Rolling 3 Year Annualized SD ", x = "", y = "Rolling 2 year SD") + theme_fmx()

roll_SD_hedge_plot
```
If the returns comparison was not convincing enough the comparison of a two year rolling SD paints an even clearer picture. Throughout the entire sample period the Hedged portfolio is more risky. Figures 4 and 5 only strengthen this argument to show that the results are strong irrespective of the lookback period. Finally the table at the end of the question calculates the correlations of both portfolios to the USD/ZAR exchange rate and finds that hedged portfolio is more negatively correlated to the USD/ZAR exchange rate. This confirms the existence of the paradox in volatility in that negatively correlated assets may produce portfolio volatilities that
are lower than the sum of its parts.
```{r}
#Lets give that table a crack
#Lets get the annulised returns for both portfolios
#Start by getting tidy data
tidy_hedged <-hedged_comp_df %>% 
    gather(Type, ret, -date) %>% 
    tbl_xts(., cols_to_xts = ret, spread_by = Type)

#Now lets use the performance analytics package to get the annulized returns and std devs following the practical 

hedge_plot <- 
    bind_rows(
        tidy_hedged %>% tail(12) %>% PerformanceAnalytics::Return.annualized(., scale = 12) %>% data.frame() %>% mutate(Freq = "A"),
        tidy_hedged %>% tail(36) %>% PerformanceAnalytics::Return.annualized(., scale = 12) %>% data.frame() %>% mutate(Freq = "B"),
        tidy_hedged %>% tail(60) %>% PerformanceAnalytics::Return.annualized(., scale = 12) %>% data.frame() %>% mutate(Freq = "C")
    )%>% data.frame() %>% gather(Type, mu, -Freq)
to_string <- as_labeller(c(`A` = "1 Year", `B` = "3 Years", `C` = "5 Years"))

g <- hedge_plot %>% 
ggplot() + 
    
  geom_bar( aes(Type, mu, fill = Type), stat="identity") + 
    
  facet_wrap(~Freq, labeller = to_string, nrow = 1) + 
    
  labs(x = "", y = "Returns (Ann.)" )+
    theme_fmx()
g
```

```{r}
#Now I plot a similar graph instead looking at the volatility
hedge_plot_SD <- 
    bind_rows(
        tidy_hedged %>% tail(12) %>% PerformanceAnalytics::StdDev.annualized(., scale = 12) %>% data.frame() %>% mutate(Freq = "A"),
        tidy_hedged %>% tail(36) %>% PerformanceAnalytics::StdDev.annualized(., scale = 12) %>% data.frame() %>% mutate(Freq = "B"),
        tidy_hedged %>% tail(60) %>% PerformanceAnalytics::StdDev.annualized(., scale = 12) %>% data.frame() %>% mutate(Freq = "C")
    )%>% data.frame() %>% gather(Type, mu, -Freq)
to_string <- as_labeller(c(`A` = "1 Year", `B` = "3 Years", `C` = "5 Years"))

Vol_annulised <- hedge_plot_SD %>% 
ggplot() + 
    
  geom_bar( aes(Type, mu, fill = Type), stat="identity") + 
    
  facet_wrap(~Freq, labeller = to_string, nrow = 1) + 
    
  labs(x = "", y = "Vol (Ann.)" )+
    theme_fmx()
Vol_annulised
```

```{r}
#Lastly I just want to plot the correlations between exchange rate and the portfolios
rho_hedge<- hedged_comp_df %>% 
    left_join(., ex_ret, by = "date") %>% 
    mutate(hedge_rho = cor(Hedged, currency_ret)) %>% 
    mutate(unhedged_rho = cor(Unhedged, currency_ret)) %>% 
    select(date, hedge_rho, unhedged_rho) %>% 
    rename("Hedged"= "hedge_rho", "Unhedged" = "unhedged_rho") %>% 
    gather(Type, Correlation, -date) %>% 
    group_by(Type) %>% 
    summarise(Correlation= mean(Correlation))


kableExtra::kable(rho_hedge)

```

# Question 3
```{r}
#read in the data
ALSI <- read_rds("Question 3/data/ALSI.rds")
RebDays <- read_rds("Question 3/data/Rebalance_days.rds")
ZAR <- read_rds("Question 3/data/Monthly_zar.rds")
swix <- read_rds("Question 3/data/Capped_SWIX.rds")


```



## Introduction \label{Introduction}
This question presents an analysis of the return profiles of the SWIX (J403) and the ALSI (J203). I begin by simply plotting the cumulative returns of both funds with all sectors and market caps. I then break down both indexes by sector and market caps. I then provide insights into the volatility of both indexes subject to high a low volatility periods of the USD/ZAR exchange rate. Lastly, I present the cumulative return profiles of both indexes subject to different constrains on the capping. This report provides evidence that the methodology used for the J203 (ALSI) provides higher returns and is influenced less by exchange rate volatility.
```{r}
#The question has three parts
#1) Compare the SWIX and ALSI (two funds) and then within the ALSI we need to compare rreturns of sectors and cap size
#1) stratefy using the rand and then I want to redo point 1
#3) capping 5%, 10% and uncapped
```
```{r}
# #We can use the rmsfun safe return portfolio if we get the weights
# 
#   sectors<- unique(ALSI$Sector) 
# 
# #for each sector we need to reweight the tickers in each sector
# 
# #Lets find returns for resources first and then we can redo ir for all other sectors and indexes or try and make a function if we have time
# resource_wts <- ALSI %>% 
#     filter(Sector == "Resources") %>% 
#     group_by(date) %>% 
#     mutate(J203 = J203/sum(J203)) %>% #the weights will now sum to 1
#     mutate(J403= J403/sum(J403)) %>% 
#     ungroup() 
# 
# res_rts <- resource_wts %>% 
#     select(date, Tickers, Return)
# #I actually need to separate the weights so we can find the return for both funds
# j2_wts <- resource_wts %>% 
#     select(date, Tickers, J203 ) %>% 
#     spread(Tickers,J203) %>% 
#     tbl_xts()
# j2_wts[is.na(j2_wts)] <- 0
# 
# 
# j4_wts <- resource_wts %>% 
#     select(date, Tickers, J403) %>% 
#     tbl_xts()
# 
# #We need to get the returns for each ticker as well and put it into xts 
# resource_returns <- resource_wts %>% 
#     select(date, Tickers, Return) %>% 
#     spread(Tickers, Return) %>% 
#     tbl_xts()
# resource_returns[is.na(resource_returns)] <- 0 #the function cannot handle NAs
# 
# #?Safe_Return.portfolio    
# j2_resport_rts <- Safe_Return.portfolio(resource_returns, j2_wts, lag_weights = TRUE, contribution = TRUE, verbose = TRUE, value = 1000, geometric = TRUE) 
# 
# j2_res_cont<- 
#     j2_resport_rts$"contribution" %>% xts_tbl()
# 
# j2_res_BPwts<-
#     j2_resport_rts$"BOP.Weight" %>% xts_tbl() 
# 
# j2_resValue <- 
#     j2_resport_rts$BOP.Value %>% xts_tbl() 
# 
# #Let's Bind all of this together
# df_res_rtsj2 <- 
#     left_join(res_rts, j2_res_BPwts %>% gather(Tickers, weights, -date), by = c("date", "Tickers")) %>% 
#     
#     left_join(., j2_resValue %>% gather(Tickers, value_held, -date),
#                 by = c("date", "Tickers") ) %>%  
#     
#     left_join(., j2_res_cont %>%  gather(Tickers, Contribution, -date),
#                 by = c("date", "Tickers"))
# 
# df_j2_resport<- df_res_rtsj2 %>% group_by(date) %>% summarise(Resources = sum(Return*weights, na.rm =TRUE))%>% filter(PortfolioReturn != 0)


    
```

```{r}
#I want to plot the cumulative returns of the J403, J203 and SWIX

#we have the weights so now I just follow the prac 
j403_wts <- ALSI %>% 
    select(date, Tickers, J403) %>% spread(Tickers, J403) %>% tbl_xts()
j403_wts[is.na(j403_wts)] <- 0

j203_wts <- ALSI %>% 
    select(date, Tickers, J203) %>% spread(Tickers, J203) %>% tbl_xts()
j203_wts[is.na(j203_wts)] <- 0


df_Returns <- ALSI %>% 
    select(date, Tickers, Return) %>%  spread(Tickers, Return)
df_Returns[is.na(df_Returns)] <- 0
xts_df_Returns <- df_Returns %>% tbl_xts()

J403_RetPort <- 
      rmsfuns::Safe_Return.portfolio(xts_df_Returns, 
                                     
                       weights = j403_wts, lag_weights = TRUE,
                       
                       verbose = TRUE, contribution = TRUE, 
                       
                       value = 1000, geometric = TRUE) 

    J203_RetPort <- 
      rmsfuns::Safe_Return.portfolio(xts_df_Returns, 
                                     
                       weights = j203_wts, lag_weights = TRUE,
                       
                       verbose = TRUE, contribution = TRUE, 
                       
                       value = 1000, geometric = TRUE) 

# Clean and save portfolio returns and weights:
J403_Contribution <- 
      J403_RetPort$"contribution" %>% xts_tbl() 

J403_BPWeight <- 
  
      J403_RetPort$"BOP.Weight" %>% xts_tbl() 

J403_BPValue <- 
  
     J403_RetPort$"BOP.Value" %>% xts_tbl()  
    
# Clean and save portfolio returns and weights:
J203_Contribution <- 
      J203_RetPort$"contribution" %>% xts_tbl() 

J203_BPWeight <- 
      J203_RetPort$"BOP.Weight" %>% xts_tbl()  

J203_BPValue <- 
      J203_RetPort$"BOP.Value" %>% xts_tbl()
    

    
    # Let's bind all of these together now:
    
    df_port_return_J403 <- 
      left_join(ALSI %>% select(date, Tickers, Return) ,
                J403_BPWeight %>% gather(Tickers, weight, -date),
                by = c("date", "Tickers") ) %>% 
      
      left_join(.,
                J403_BPValue %>% gather(Tickers, value_held, -date),
                by = c("date", "Tickers") ) %>% 
      
      left_join(.,
                J403_Contribution %>% gather(Tickers, Contribution, -date),
                by = c("date", "Tickers"))

    df_port_return_J203 <- 
      left_join(ALSI %>% select(date, Tickers, Return),
                J203_BPWeight %>% gather(Tickers, weight, -date),
                by = c("date", "Tickers") ) %>% 
      
      left_join(.,
               J203_BPValue %>% gather(Tickers, value_held, -date),
                by = c("date", "Tickers") ) %>% 
      
      left_join(.,
                J203_Contribution %>% gather(Tickers, Contribution, -date),
                by = c("date", "Tickers"))

# Calculate Portfolio Returns:
df_Portf_J403 <- 
    df_port_return_J403 %>% group_by(date) %>% summarise(PortfolioReturn = sum(Return*weight, na.rm =TRUE)) %>% 
      filter(PortfolioReturn != 0)
      
# Calculate Portfolio Returns:
df_Portf_J203 <- 
    df_port_return_J203 %>% group_by(date) %>% summarise(PortfolioReturn = sum(Return*weight, na.rm =TRUE)) %>% 
      filter(PortfolioReturn != 0)
#Now lets join the dfs
alsi_rets<-
    left_join(df_Portf_J203 %>% rename("ALSI"= "PortfolioReturn"), df_Portf_J403 %>% rename("SWIX"= "PortfolioReturn"), by = "date") %>% 
    gather(Index, ret, -date)



```

```{r}
#Lets plot them now 
compar_plot<- alsi_rets %>% 
    arrange(date) %>% 
    group_by(Index) %>% 
    mutate(cum_rts = cumprod(1+ret)) %>% 
    select(-ret) %>% 
    ungroup() %>% 
    ggplot()+
    geom_line(aes(date, cum_rts, color = Index))+
    fmxdat::theme_fmx()+
    labs(title = "Cumulative Returns of Both Indexes",  x = "Date", y = "Cumulative Returns")

compar_plot
```
The figure above highlights that ALSI has a higher cumulative return that the SWIX
```{r}

#I created a function that filters the data to each sector, adjusts the weight so all the weights of each stock in th sector sum to one (REMEMBER this). then I follow practical 2 where i apply the rmsfun::Safe_Return.portfolio to get the final portfolio returns


#apply the function to all of the sectors for both indexes and then
Resources_j4 <-calculate_portfolio_returns(data = ALSI, sector_name = "Resources", fund_name = "J403") %>% 
    rename("Resources"= "PortfolioReturn" )

Financial_j4<- calculate_portfolio_returns(data = ALSI, sector_name = "Financials", fund_name = "J403") %>% 
    rename("Financials"= "PortfolioReturn")

Industrials_j4 <- calculate_portfolio_returns(data = ALSI, sector_name = "Industrials", fund_name = "J403") %>% 
    rename("Industrials"= "PortfolioReturn")

Property_j4 <-  calculate_portfolio_returns(data = ALSI, sector_name = "Property", fund_name = "J403") %>% 
    rename("Property"= "PortfolioReturn")

#now do it again for fund J203
Resources_j2 <-calculate_portfolio_returns(data = ALSI, sector_name = "Resources", fund_name = "J203") %>% 
    rename("Resources"= "PortfolioReturn" )

Financial_j2<- calculate_portfolio_returns(data = ALSI, sector_name = "Financials", fund_name = "J203") %>% 
    rename("Financials"= "PortfolioReturn")

Industrials_j2 <- calculate_portfolio_returns(data = ALSI, sector_name = "Industrials", fund_name = "J203") %>% 
    rename("Industrials"= "PortfolioReturn")

Property_j2 <-  calculate_portfolio_returns(data = ALSI, sector_name = "Property", fund_name = "J203") %>% 
    rename("Property"= "PortfolioReturn")   

#Now I just need to join them all together
#Unfortunatly the function did not work perfectly and I cannot identify the issue, so i needed to use the impute returns function to ensure that i could plot the returns
Sectors_returns_j4 <-
    left_join(Resources_j4, Financial_j4, by = "date") %>% 
    left_join(., Industrials_j4, by ="date") %>% 
    left_join(., Property_j4, by = "date") %>% 
    impute_missing_returns(., impute_returns_method  = "Drawn_Distribution_Own") %>% 
    gather(Sector, ret, -date)

Sectors_returns_j2<- 
     left_join(Resources_j4, Financial_j2, by = "date") %>% 
    left_join(., Industrials_j2, by ="date") %>% 
    left_join(., Property_j2, by = "date")%>% 
     impute_missing_returns(., impute_returns_method  = "Drawn_Distribution_Own") %>% 
    gather(Sector, ret, -date)
   
    
 


```

```{r}
#Now lets plot the cumulative returns for both funds by sector
cum_sectors_j4<- Sectors_returns_j4 %>% 
    arrange(date) %>% 
    group_by(Sector) %>% 
    mutate(cum_rts = cumprod(1+ret)) %>% 
    select(-ret) %>% 
    ungroup() %>% 
    ggplot()+
    geom_line(aes(date, cum_rts, color = Sector))+
    fmxdat::theme_fmx()+
    labs(title = "Cumulative Returns of SWIX", subtitle = "by Sector", x = "Date", y = "Cumulative Returns")

cum_sectors_j4
```

```{r}
cum_sectors_j2<- Sectors_returns_j2 %>% 
    arrange(date) %>% 
    group_by(Sector) %>% 
    mutate(cum_rts = cumprod(1+ret)) %>% 
    select(-ret) %>% 
    ungroup() %>% 
    ggplot()+
    geom_line(aes(date, cum_rts, color = Sector))+
    fmxdat::theme_fmx()+
    labs(title = "Cumulative Returns of ALSI", subtitle = "By Sector", x = "Date", y = "Cumulative Returns")

cum_sectors_j2 
```

The Figures above show key differences between how the indexes weight stocks in each sector. It appears that the Industrials sector is the largest driver of the higher returns of the ALSI.
```{r}
#I now ammend the previous function so that it filters for the cap rather than sector and then it follows exactly the same process

# caps<- unique(ALSI$Index_Name) 

#follow the same process and get the returns for the different caps
large_j4 <-calculate_portfolio_returns_cap(data = ALSI, cap_name = "Large_Caps", fund_name = "J403") %>% 
    rename("Large_SWIX"= "PortfolioReturn" )

mid_j4 <-calculate_portfolio_returns_cap(data = ALSI, cap_name = "Mid_Caps", fund_name = "J403") %>% 
    rename("Mid_SWIX"= "PortfolioReturn" )

small_j4 <-calculate_portfolio_returns_cap(data = ALSI, cap_name = "Small_Caps", fund_name = "J403") %>% 
    rename("Small_SWIX"= "PortfolioReturn" )

large_j2 <-calculate_portfolio_returns_cap(data = ALSI, cap_name = "Large_Caps", fund_name = "J403") %>% 
    rename("Large_ALSI"= "PortfolioReturn" )

mid_j2 <-calculate_portfolio_returns_cap(data = ALSI, cap_name = "Mid_Caps", fund_name = "J403") %>% 
    rename("Mid_ALSI"= "PortfolioReturn" )

small_j2 <-calculate_portfolio_returns_cap(data = ALSI, cap_name = "Small_Caps", fund_name = "J403") %>% 
    rename("Small_ALSI"= "PortfolioReturn" )


#join each fund
cap_ret_j4 <-
    left_join(large_j4, mid_j4, by = "date") %>% 
    left_join(.,small_j4, by = "date") %>% 
    impute_missing_returns(., impute_returns_method  = "Drawn_Distribution_Own") %>% 
    gather(Cap, ret, -date)

cap_ret_j2 <-
    left_join(large_j2, mid_j2, by = "date") %>% 
    left_join(.,small_j2, by = "date") %>% 
    impute_missing_returns(., impute_returns_method  = "Drawn_Distribution_Own") %>% 
    gather(Cap, ret, -date)

```


```{r}
cum_cap_j4<- cap_ret_j4 %>% 
    arrange(date) %>% 
    group_by(Cap) %>% 
    mutate(cum_rts = cumprod(1+ret)) %>% 
    select(-ret) %>% 
    ungroup() %>% 
    ggplot()+
    geom_line(aes(date, cum_rts, color = Cap))+
    fmxdat::theme_fmx()+
    labs(title = "Cumulative Returns of SWIX", subtitle = "By Market Cap", x = "Date", y = "Cumulative Returns")

cum_cap_j4
```

```{r}
cum_cap_j2<- cap_ret_j2 %>% 
    arrange(date) %>% 
    group_by(Cap) %>% 
    mutate(cum_rts = cumprod(1+ret)) %>% 
    select(-ret) %>% 
    ungroup() %>% 
    ggplot()+
    geom_line(aes(date, cum_rts, color = Cap))+
    fmxdat::theme_fmx()+
    labs(title = "Cumulative Returns of ALSI", subtitle = "by Market Cap", x = "Date", y = "Cumulative Returns")

 cum_cap_j2
```
Moving on to index sizes, the figures above show that there is very little difference between index sizes. The returns for small caps of ALSI are slightly higher than for SWIX. Beyond that there is little difference, thus I would argue that the composition within sectors is a larger driver of the differences in returns.

## Stratification

```{r}
Idxs <- alsi_rets

Idxs <-
  
  Idxs %>% 
    mutate(Year = format(date, "%Y")) %>% 
    
    group_by(Index) %>% 
  
  mutate(Top = quantile(ret, 0.99), Bot = quantile(ret, 0.01)) %>% 
  
  mutate(ret = ifelse(ret > Top, Top, 
                         
                         ifelse(ret < Bot, Bot, ret))) %>% ungroup()

ZARSD <- ZAR %>% 
    filter(date>lubridate::ymd(20130101)) %>% #to match the index data
    mutate(Year = format(date, "%Y")) %>% #unlike the prac we have montly data so we need to look at yearly rather
    arrange(date) %>% 
    mutate(Return= value/lag(value)-1) %>% 
  
  group_by(Year) %>% summarise(SD = sd(Return)*sqrt(12)) %>% 
  
  # Top Decile Quantile overall (highly volatile month for ZAR:
  mutate(TopQtile = quantile(SD, 0.8, na.rm = TRUE),
         
         BotQtile = quantile(SD, 0.2, na.rm = TRUE))



Hi_Vol <- ZARSD %>% filter(SD > TopQtile) %>% pull(Year)

Low_Vol <- ZARSD %>% filter(SD < BotQtile) %>% pull(Year)

Perf_comparisons <- function(Idxs, Ys, Alias){
  # For stepping through uncomment:
  # YMs <- Hi_Vol
  Unconditional_SD <- 
    
  Idxs %>% 
    
    group_by(Index) %>% 
    
    mutate(Full_SD = sd(ret) * sqrt(12)) %>% 
    
    filter(Year %in% Ys) %>% 
    
    summarise(SD = sd(ret) * sqrt(12), across(.cols = starts_with("Full"), .fns = max)) %>% 
    
    arrange(desc(SD)) %>% mutate(Period = Alias) %>% 
    
    group_by(Index) %>% 
    
    mutate(Ratio = SD / Full_SD)
    
    Unconditional_SD
  
}

perf_hi <- Perf_comparisons(Idxs, Ys = Hi_Vol, Alias = "High_Vol")

perf_lo <- Perf_comparisons(Idxs, Ys = Low_Vol, Alias = "Low_Vol")

kableExtra::kable(perf_hi)
```

```{r}
kableExtra::kable(perf_lo)
```
The table shows that in high volatile periods of the exchange rate both the SWIX and the ALSI have increased volatility as well but the SWIX is effected more than the ALSI. There is little to no difference during low volatility periods.
## Capping
```{r}
#Let's follow the extra prac 1 for this 
#start with J403
Rebalance_days <- RebDays %>% 
    filter(Date_Type == "Reb Trade Day") %>% # only concerned on the day that we are actually rebalancing
    pull(date)

rebalance_col <- ALSI %>%
    rename("weight"= "J403") %>% #the functions use weight so this makes it easier for me later on
    filter(date %in% Rebalance_days ) %>% 
    mutate(RebalanceTime = format(date, "%Y%B%A")) %>% 
    group_by(RebalanceTime) %>% 
    arrange(desc(weight)) %>% 
    ungroup() %>% 
    arrange(date) %>% 
    select(date, Tickers, weight, RebalanceTime )

# df_Cons <- rebalance_col %>% filter(date == first(date))
#  W_Cap = 0.8
  

# Now, to map this across all the dates, we can use purrr::map_df as follows:
  Capped_df <- 
    
    rebalance_col %>% 
    # Split our df into groups (where the groups here are the rebalance dates:
    group_split(RebalanceTime) %>% 
    
    # Apply the function Proportional_Cap_Foo to each rebalancing date:
    map_df(~Proportional_Cap_Foo(., W_Cap = 0.08) ) %>% select(-RebalanceTime)
    

wts<-
    Capped_df %>% 
    tbl_xts(cols_to_xts = weight, spread_by = Tickers)

rts <- ALSI %>% 
    filter(Tickers %in% unique(Capped_df$Tickers) ) %>% 
  
  tbl_xts(cols_to_xts = Return, spread_by = Tickers)

wts[is.na(wts)] <- 0

rts[is.na(rts)] <- 0

Idx <- 
  rmsfuns::Safe_Return.portfolio(R = rts, weights = wts, lag_weights = T) %>% 
  
  # Let's make this a tibble:
  xts_tbl() %>% 
  
  rename("J403" = "portfolio.returns")



```


```{r}
#I wrap the  proportional cap foo Function such that I can just input the fund name and weight cap and it returns capped portfolio returns

#now use the function to get the returns and get ready to "plot this bugga"
alsi_5 <- rebalance_and_calculate_returns(ALSI, J203, w_cap = 0.05) %>% 
    rename("ALSI"= "J203") %>% 
    mutate(Index = "5%")

alsi_10 <- rebalance_and_calculate_returns(ALSI, J203, w_cap = 0.10) %>% 
    rename("ALSI"= "J203") %>% 
    mutate(Index = "10%")

alsi_un <- rebalance_and_calculate_returns(ALSI, J203, w_cap = 1) %>% 
    rename("ALSI"= "J203") %>% 
    mutate(Index = "No Cap")

swix_5 <- rebalance_and_calculate_returns(ALSI, J403, w_cap = 0.05) %>% 
    rename("SWIX"= "J403") %>% 
    mutate(Index = "5%")

swix_10 <- rebalance_and_calculate_returns(ALSI, J403, w_cap = 0.1) %>% 
    rename("SWIX"= "J403") %>% 
    mutate(Index = "10%")

swix_un <- rebalance_and_calculate_returns(ALSI, J403, w_cap = 1) %>% 
    rename("SWIX"= "J403") %>% 
    mutate(Index = "No Cap")


# Combine ALSI data frames
alsi_combined <- bind_rows(
  alsi_5 %>% select(date, ALSI, Index),
  alsi_10 %>% select(date, ALSI, Index),
  alsi_un %>% select(date, ALSI, Index)
)

# Combine SWIX data frames
swix_combined <- bind_rows(
  swix_5 %>% select(date, SWIX, Index),
  swix_10 %>% select(date, SWIX, Index),
  swix_un %>% select(date, SWIX, Index)
)

# Merge ALSI and SWIX data frames based on the "date" column
idx <- full_join(alsi_combined, swix_combined, by = c("date","Index")) %>% 
    select(date, SWIX, ALSI, Index)


```

```{r}
# Let's plot this bugger
idx %>% 
  mutate(swix = cumprod(1+SWIX)) %>% 
    mutate(alsi = cumprod(1+ALSI)) %>% 
  
  ggplot(., aes(x = date)) +
  geom_line(aes(y = alsi, color = "ALSI"), size = 1) +
  geom_line(aes(y = swix, color = "SWIX"), size = 1) +
  facet_wrap(~Index, scales = "free_y", ncol = 1) +
  labs(title = "ALSI and SWIX Over Time", subtitle = "With different caps",  x = "Date", y = "Value") +
  scale_color_manual(values = c(ALSI = "blue", SWIX = "red"))+
    theme_fmx()
```
The Figure above shows that the ALSI is more susceptible decreased returns from the imposition of capping but under all three restrictions still outperforms the SWIX. 